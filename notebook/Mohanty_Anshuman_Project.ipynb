{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d2684c-c854-481d-9825-5fabbcc75a6c",
   "metadata": {},
   "source": [
    "<center><h1>Mohanty_Anshuman_Project</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bff3be-b6d7-4cbc-9726-637b508e0adc",
   "metadata": {},
   "source": [
    "Name: Anshuman Mohanty\n",
    "<br>\n",
    "Github Username: AnshumanMohanty-2001\n",
    "<br>\n",
    "USC ID: 4257570790"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57656a91-9b84-4505-96f1-3645600384fa",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4439a3fe-7044-47ec-bf72-c1434ef30b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Flatten, Dropout, Conv1D, MaxPooling1D, Input\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead47084-fd87-452d-8e2d-764d4c8bcef2",
   "metadata": {},
   "source": [
    "## Data Exploration and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0141cabc-c0b0-4e5f-aa57-76641c6a3672",
   "metadata": {},
   "source": [
    "<b>Code Referenced from [1 - 22]</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe90862-af4e-415e-9f78-0e4077d88d1a",
   "metadata": {},
   "source": [
    "i. You can use binary encoding for the sentiments , i.e y = 1 for positive sentiments and y = −1 for negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c451a400-7f04-4e35-9722-b5cc9030b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '../Data/'\n",
    "\n",
    "all_files_pos, all_files_neg = [list() for _ in range(2)]\n",
    "neg_list = []\n",
    "pos_list = []\n",
    "\n",
    "neg_label = []\n",
    "pos_label = []\n",
    "\n",
    "pos_file_no, neg_file_no = [list() for _ in range(2)]\n",
    "\n",
    "\n",
    "for f in os.listdir(os.path.join(db_path, 'neg')):\n",
    "    with open(os.path.join(db_path, 'neg/', f), 'r') as txt_file:\n",
    "        neg_list.append(txt_file.read())\n",
    "\n",
    "for f in os.listdir(os.path.join(db_path, 'pos')):\n",
    "    with open(os.path.join(db_path, 'pos/', f), 'r') as txt_file:\n",
    "        pos_list.append(txt_file.read())\n",
    "# using one and zero for labels due to error with -1\n",
    "neg_label = [0 for _ in range(1000)]\n",
    "pos_label = [1 for _ in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a412fd40-c43e-4ae0-9980-28bd56690556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>every now and then a movie comes along from a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you've got mail works alot better than it dese...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" jaws \" is a rare film that grabs your atten...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moviemaking is a lot like being the general ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  films adapted from comic books have had plenty...      1\n",
       "1  every now and then a movie comes along from a ...      1\n",
       "2  you've got mail works alot better than it dese...      1\n",
       "3   \" jaws \" is a rare film that grabs your atten...      1\n",
       "4  moviemaking is a lot like being the general ma...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict = {'text': pos_list, 'label': pos_label}\n",
    "temp_pos_df = pd.DataFrame(pos_dict)\n",
    "temp_pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8cd42a-4724-469f-8618-8bdaa0ce79da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  plot : two teen couples go to a church party ,...      0\n",
       "1  the happy bastard's quick movie review \\ndamn ...      0\n",
       "2  it is movies like these that make a jaded movi...      0\n",
       "3   \" quest for camelot \" is warner bros . ' firs...      0\n",
       "4  synopsis : a mentally unstable man undergoing ...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_dict = {'text': neg_list, 'label': neg_label}\n",
    "temp_neg_df = pd.DataFrame(neg_dict)\n",
    "temp_neg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c90820-efb1-4999-a8d8-cdc5e9ea4549",
   "metadata": {},
   "source": [
    "ii. The data are pretty clean. Remove the punctuation and numbers from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da91d191-c764-4750-a8c2-bdbee972b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_neg_df['text'] = temp_neg_df['text'].str.replace('\\d+', '', regex=True)\n",
    "temp_pos_df['text'] = temp_pos_df['text'].str.replace('\\d+', '', regex=True)\n",
    "\n",
    "temp_neg_df['text'] = temp_neg_df['text'].str.replace('[^\\w\\s]', '', regex=True)\n",
    "temp_pos_df['text'] = temp_pos_df['text'].str.replace('[^\\w\\s]', '', regex=True)\n",
    "\n",
    "temp_neg_df['text'] = temp_neg_df['text'].str.replace('_', '', regex=True)\n",
    "temp_pos_df['text'] = temp_pos_df['text'].str.replace('_', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ab934-8a4c-416f-b6eb-8d931c330b89",
   "metadata": {},
   "source": [
    "Data is free of all punctuations and numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde9d88-e637-48c8-8fc5-90fe240c8dd5",
   "metadata": {},
   "source": [
    " iii. The name of each text file starts with cv_number. Use text files 0-699 in each class for training and 700-999 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "257e8df0-40f0-4986-b302-f30582e96cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_df = temp_pos_df.iloc[:700,:]\n",
    "test_pos_df = temp_pos_df.iloc[700:,:]\n",
    "\n",
    "train_neg_df = temp_neg_df.iloc[:700,:]\n",
    "test_neg_df = temp_neg_df.iloc[700:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a47564-1076-40f7-88d3-c79fd2b28c6e",
   "metadata": {},
   "source": [
    "Now combining the train, test and the entire dataset after shuffling the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b6c9c4-6a23-4fbe-9e8e-4fd9a0b66cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_pos_df, train_neg_df])\n",
    "train_df = train_df.sample(frac=1, random_state = 20).reset_index(drop=True)\n",
    "test_df = pd.concat([test_pos_df, test_neg_df])\n",
    "test_df = test_df.sample(frac=1, random_state = 20).reset_index(drop=True)\n",
    "\n",
    "final_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b2d35a-4e46-419a-aa74-b4b4251745e4",
   "metadata": {},
   "source": [
    "iv. Count the number of unique words in the whole dataset (train + test) and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8f3aaf-8358-4384-8b86-d3a673b4fc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Words: 46782\n"
     ]
    }
   ],
   "source": [
    "get_total_text_list = final_df['text'].tolist()\n",
    "get_text_string = ' '.join(get_total_text_list)\n",
    "total_words = word_tokenize(get_text_string)\n",
    "\n",
    "print(f'Total Unique Words: {len(set(total_words))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd678aa-3830-441d-8499-9ca12e133685",
   "metadata": {},
   "source": [
    "v. Calculate the average review length and the standard deviation of review lengths. Report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "122b2817-6155-48f3-a923-c1f229bd2c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Review Length: 644.464\n",
      "Standard deviation of Review Length: 285.0949846614977\n"
     ]
    }
   ],
   "source": [
    "final_df['tokens'] = final_df['text'].apply(word_tokenize)\n",
    "final_df['review length'] = final_df['tokens'].apply(len)\n",
    "print(f\"Average Review Length: {final_df['review length'].mean()}\")\n",
    "print(f\"Standard deviation of Review Length: {final_df['review length'].std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1c74c5-2d8c-46a3-8176-0e144a7fa251",
   "metadata": {},
   "source": [
    "vi. Plot the histogram of review lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ed31051-f599-4335-9d91-12e3188b6931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(final_df['review length'])\n",
    "plt.title('Histogram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620b685-5fc1-4e41-a50a-2f78d429f2b3",
   "metadata": {},
   "source": [
    "The histogram is slightly skewed towards the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b130f2-b8d8-4df9-8e0d-9f65a31d98dd",
   "metadata": {},
   "source": [
    "vii. To represent each text (= data point), there are many ways. In NLP/Deep Learning terminology, this task is called tokenization. It is common to represent text using popularity/ rank of words in text. The most common word in the text will be represented as 1, the second most common word will be\n",
    " represented as 2, etc. Tokenize each text document using this method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7354922-d9c2-4db9-b9d3-ff0dc57bbf10",
   "metadata": {},
   "source": [
    "Tokenizing the train and test sets for top 5000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c0307c0-2509-4892-b68d-c26db8f7e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokn = Tokenizer(num_words = 5000)\n",
    "tokn.fit_on_texts(final_df['text'])\n",
    "se = tokn.texts_to_sequences(final_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ae308-ab00-4536-adc4-8eb6b3d65773",
   "metadata": {},
   "source": [
    "viii. Select a review length L that 70% of the reviews have a length below it. If you feel more adventurous, set the threshold to 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a022ffb-da0a-4ba8-9d99-256ddb621dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold value for review length at 70%: 737\n",
      "Threshold value for review length at 90%: 993\n"
     ]
    }
   ],
   "source": [
    "L_val = int(np.percentile(final_df['review length'], 70))\n",
    "print(f'Threshold value for review length at 70%: {L_val}')\n",
    "L_temp = int(np.percentile(final_df['review length'], 90))\n",
    "print(f'Threshold value for review length at 90%: {L_temp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e0c74-c9c7-4b34-b799-57eae85cf55f",
   "metadata": {},
   "source": [
    "I will be using L at 70% threshold for subsequent steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f30a3f-09fc-41ef-85fb-76bb34b3449e",
   "metadata": {},
   "source": [
    "ix. Truncate reviews longer than L words and zero-pad reviews shorter than L so that all texts (= data points) are of length L."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270619e-b7ca-407d-b783-32fffb866e59",
   "metadata": {},
   "source": [
    "I have chosen padding = post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "19ec03c0-f7cb-4865-8c12-85581f2a6605",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_list = pad_sequences(se, padding='pre', truncating='post', maxlen = L_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "34fcb4e8-2335-4a64-a737-fb8d1d01353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd_list[:1400]\n",
    "y_train = train_df['label']\n",
    "X_test = pd_list[1400:]\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3c4949-0d90-4856-874d-02eab4a7a4f8",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d20bf39-cb5e-4381-ac38-2a5daf1d5a59",
   "metadata": {},
   "source": [
    "<b>Referenced from [23 - 24]</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ad42dde8-7e2c-43a1-9ea0-25014112485e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "we_model = Sequential()\n",
    "we_model.add(Embedding(5000, 32, input_length =L_val))\n",
    "we_model.add(Flatten())\n",
    "\n",
    "ip_x_train_em = we_model.predict(X_train)\n",
    "ip_x_test_em = we_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8d219e26-8ee0-4442-ac75-21bcb93d49b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00466231 -0.00699896  0.00821758 ...  0.03204398  0.00808956\n",
      "  -0.01007963]\n",
      " [-0.02527197 -0.02592266  0.0234389  ...  0.00555962  0.01751277\n",
      "  -0.00413533]\n",
      " [-0.00466231 -0.00699896  0.00821758 ...  0.01457539 -0.01895883\n",
      "   0.02367387]\n",
      " ...\n",
      " [ 0.01405472  0.02898509 -0.03452066 ... -0.00134988  0.00464506\n",
      "  -0.049989  ]\n",
      " [-0.00466231 -0.00699896  0.00821758 ...  0.01491498  0.00384467\n",
      "  -0.02321517]\n",
      " [-0.00466231 -0.00699896  0.00821758 ...  0.04571695  0.00884359\n",
      "   0.03458077]]\n"
     ]
    }
   ],
   "source": [
    "print(ip_x_train_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c40b714b-c134-43c8-96cd-5ecb7ec93387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03998373  0.01938257 -0.00822104 ...  0.02638685 -0.03851936\n",
      "   0.00734724]\n",
      " [-0.02921168 -0.03806461  0.00430651 ... -0.04629165  0.00493003\n",
      "  -0.04220878]\n",
      " [-0.00466231 -0.00699896  0.00821758 ...  0.03314951  0.00451306\n",
      "   0.03302195]\n",
      " ...\n",
      " [-0.00466231 -0.00699896  0.00821758 ...  0.03611746  0.02853684\n",
      "  -0.01493963]\n",
      " [ 0.00478754  0.01070511  0.04007572 ... -0.04387065  0.01985922\n",
      "   0.01671561]\n",
      " [ 0.00277699  0.02106814 -0.00412542 ... -0.02551821  0.04882187\n",
      "  -0.02089449]]\n"
     ]
    }
   ],
   "source": [
    "print(ip_x_test_em)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56590ff-eca6-48e0-9dee-54d388affb80",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b6fcd-7d17-490f-9b49-3cd6c873ece7",
   "metadata": {},
   "source": [
    "<b>Referenced from [25 - 27]</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a31a7cf9-8a1b-4ee3-8534-9cc10f99d1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.5081 - loss: 0.7013 - val_accuracy: 0.5667 - val_loss: 0.6867\n",
      "Epoch 2/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6074 - loss: 0.6521 - val_accuracy: 0.6417 - val_loss: 0.6309\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.2613\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6732 - loss: 0.6025 \n",
      "Training Accuracy: 0.9164285659790039\n",
      "Testing Accuracy: 0.6416666507720947\n"
     ]
    }
   ],
   "source": [
    "multi_md = Sequential()\n",
    "multi_md.add(Embedding(input_dim=5000, output_dim=32, input_length=L_val))\n",
    "multi_md.add(Flatten())\n",
    "multi_md.add(Dense(50, activation='relu'))\n",
    "multi_md.add(Dropout(0.2))\n",
    "multi_md.add(Dense(50, activation='relu'))\n",
    "multi_md.add(Dropout(0.5))\n",
    "multi_md.add(Dense(50, activation='relu'))\n",
    "multi_md.add(Dropout(0.5))\n",
    "multi_md.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "multi_md.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "multi_md.fit(X_train, y_train, epochs=2, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "_, train_acc = multi_md.evaluate(X_train, y_train)\n",
    "_, test_acc = multi_md.evaluate(X_test, y_test)\n",
    "print(f\"Training Accuracy: {train_acc}\")\n",
    "print(f\"Testing Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fca29a-ca8f-421c-ba77-3c765ac77b9a",
   "metadata": {},
   "source": [
    "## 1D CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05657588-663d-4921-9a9f-7b142bbf63cc",
   "metadata": {},
   "source": [
    "<b>Referenced from [28]</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "32ea7cc5-4b10-43cb-becb-911d8ba3ec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5211 - loss: 0.6989 - val_accuracy: 0.4983 - val_loss: 0.6923\n",
      "Epoch 2/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5059 - loss: 0.6940 - val_accuracy: 0.5450 - val_loss: 0.6925\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6338 - loss: 0.6908\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5422 - loss: 0.6925\n",
      "Train Accuracy: 0.6278571486473083\n",
      "Test Accuracy: 0.5450000166893005\n"
     ]
    }
   ],
   "source": [
    "conv_1d_model = Sequential()\n",
    "conv_1d_model.add(Embedding(input_dim=5000, output_dim=32, input_length=L_val))\n",
    "conv_1d_model.add(Conv1D(kernel_size=3, filters=32, activation='relu'))\n",
    "conv_1d_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "conv_1d_model.add(Flatten())\n",
    "conv_1d_model.add(Dense(50, activation='relu'))\n",
    "conv_1d_model.add(Dropout(0.2))\n",
    "conv_1d_model.add(Dense(50, activation='relu'))\n",
    "conv_1d_model.add(Dropout(0.5))\n",
    "conv_1d_model.add(Dense(50, activation='relu'))\n",
    "conv_1d_model.add(Dropout(0.5))\n",
    "conv_1d_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "conv_1d_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "conv_1d_model.fit(X_train, y_train, epochs=2, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "_, train_acc = conv_1d_model.evaluate(X_train, y_train)\n",
    "_, test_acc = conv_1d_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b57396-8c8b-4f43-9b15-3cbd259ff744",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e617fd3-7133-4b21-9ef9-4e321a3368af",
   "metadata": {},
   "source": [
    "<b>Referenced from [29 - 30]</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d652c331-0057-49ec-a4f0-491f44dc7d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 109ms/step - accuracy: 0.5202 - loss: 0.6921 - val_accuracy: 0.5900 - val_loss: 0.6710\n",
      "Epoch 2/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - accuracy: 0.7667 - loss: 0.5398 - val_accuracy: 0.7267 - val_loss: 0.5956\n",
      "Epoch 3/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - accuracy: 0.9252 - loss: 0.1992 - val_accuracy: 0.7183 - val_loss: 0.6787\n",
      "Epoch 4/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - accuracy: 0.9707 - loss: 0.0943 - val_accuracy: 0.7133 - val_loss: 0.9005\n",
      "Epoch 5/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - accuracy: 0.9875 - loss: 0.0342 - val_accuracy: 0.6900 - val_loss: 1.0238\n",
      "Epoch 6/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - accuracy: 0.9947 - loss: 0.0247 - val_accuracy: 0.7200 - val_loss: 1.2346\n",
      "Epoch 7/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.9938 - loss: 0.0191 - val_accuracy: 0.6750 - val_loss: 1.0593\n",
      "Epoch 8/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.9954 - loss: 0.0235 - val_accuracy: 0.7017 - val_loss: 1.4156\n",
      "Epoch 9/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.9996 - loss: 0.0043 - val_accuracy: 0.6767 - val_loss: 1.5511\n",
      "Epoch 10/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 115ms/step - accuracy: 0.9919 - loss: 0.0239 - val_accuracy: 0.6967 - val_loss: 1.3361\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.9995 - loss: 0.0033\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7140 - loss: 1.2370\n",
      "Train Accuracy: 0.9985714554786682\n",
      "Test Accuracy: 0.6966666579246521\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=5000, output_dim=32, input_length=L_val))\n",
    "model_lstm.add(LSTM(32, dropout=0.2))\n",
    "model_lstm.add(Dense(256, activation='relu'))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_lstm.fit(X_train, y_train, epochs=10, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "_, train_accuracy = model_lstm.evaluate(X_train, y_train)\n",
    "_, test_accuracy = model_lstm.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a3ca2-7008-40b3-b216-5f741dd09e21",
   "metadata": {},
   "source": [
    "## Additional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb0d56a-7daa-4e32-9738-012903b8d163",
   "metadata": {},
   "source": [
    "In this section, I have tried out with padding = post. Following is the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16d6b8-1ece-4498-83a6-5263276d7119",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d425316-f6ed-439f-b03b-1555ca2a1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_list = pad_sequences(se, padding='post', truncating='post', maxlen = L_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe024aa2-649a-4014-87a8-8285bd99fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd_list[:1400]\n",
    "y_train = train_df['label']\n",
    "X_test = pd_list[1400:]\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c833da3-b756-4004-93f2-cf26eafcbaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "we_model = Sequential()\n",
    "we_model.add(Embedding(5000, 32, input_length =L_val))\n",
    "we_model.add(Flatten())\n",
    "\n",
    "ip_x_train_em = we_model.predict(X_train)\n",
    "ip_x_test_em = we_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe1bc1-1ff5-4ee3-8a16-7a2964db680e",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a849218-3aac-40e9-b3f9-b7276f896fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.5293 - loss: 0.7035 - val_accuracy: 0.5417 - val_loss: 0.6873\n",
      "Epoch 2/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5504 - loss: 0.6832 - val_accuracy: 0.6267 - val_loss: 0.6634\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8132 - loss: 0.5415\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6460 - loss: 0.6598 \n",
      "Training Accuracy: 0.8100000023841858\n",
      "Testing Accuracy: 0.6266666650772095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "multi_md = Sequential()\n",
    "multi_md.add(Embedding(input_dim=5000, output_dim=32, input_length=L_val))\n",
    "multi_md.add(Flatten())\n",
    "multi_md.add(Dense(50, activation='relu'))\n",
    "multi_md.add(Dropout(0.2))\n",
    "multi_md.add(Dense(50, activation='relu'))\n",
    "multi_md.add(Dropout(0.5))\n",
    "multi_md.add(Dense(50, activation='relu'))\n",
    "multi_md.add(Dropout(0.5))\n",
    "multi_md.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "multi_md.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "multi_md.fit(X_train, y_train, epochs=2, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "_, train_acc = multi_md.evaluate(X_train, y_train)\n",
    "_, test_acc = multi_md.evaluate(X_test, y_test)\n",
    "print(f\"Training Accuracy: {train_acc}\")\n",
    "print(f\"Testing Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3d9694-c5bd-48f6-b083-970663ecf2b9",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dada98bc-2c00-4612-b4aa-2c173bff13a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4712 - loss: 0.6992 - val_accuracy: 0.5317 - val_loss: 0.6929\n",
      "Epoch 2/2\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5571 - loss: 0.6876 - val_accuracy: 0.6017 - val_loss: 0.6876\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7206 - loss: 0.6758\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5890 - loss: 0.6875\n",
      "Train Accuracy: 0.7300000190734863\n",
      "Test Accuracy: 0.6016666889190674\n"
     ]
    }
   ],
   "source": [
    "conv_1d_model = Sequential()\n",
    "conv_1d_model.add(Embedding(input_dim=5000, output_dim=32, input_length=L_val))\n",
    "conv_1d_model.add(Conv1D(kernel_size=3, filters=32, activation='relu'))\n",
    "conv_1d_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "conv_1d_model.add(Flatten())\n",
    "conv_1d_model.add(Dense(50, activation='relu'))\n",
    "conv_1d_model.add(Dropout(0.2))\n",
    "conv_1d_model.add(Dense(50, activation='relu'))\n",
    "conv_1d_model.add(Dropout(0.5))\n",
    "conv_1d_model.add(Dense(50, activation='relu'))\n",
    "conv_1d_model.add(Dropout(0.5))\n",
    "conv_1d_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "conv_1d_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "conv_1d_model.fit(X_train, y_train, epochs=2, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "_, train_acc = conv_1d_model.evaluate(X_train, y_train)\n",
    "_, test_acc = conv_1d_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f28c0-88d8-47ba-b48e-f5a3b504c596",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1092f411-a924-42fb-844d-62a820b8c15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 120ms/step - accuracy: 0.5096 - loss: 0.6940 - val_accuracy: 0.5383 - val_loss: 0.6906\n",
      "Epoch 2/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 125ms/step - accuracy: 0.5342 - loss: 0.6915 - val_accuracy: 0.5350 - val_loss: 0.6893\n",
      "Epoch 3/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 131ms/step - accuracy: 0.5383 - loss: 0.6663 - val_accuracy: 0.5383 - val_loss: 0.7069\n",
      "Epoch 4/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 136ms/step - accuracy: 0.5924 - loss: 0.6190 - val_accuracy: 0.5200 - val_loss: 0.7028\n",
      "Epoch 5/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 136ms/step - accuracy: 0.6248 - loss: 0.6059 - val_accuracy: 0.5017 - val_loss: 0.8182\n",
      "Epoch 6/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 133ms/step - accuracy: 0.6153 - loss: 0.5885 - val_accuracy: 0.5400 - val_loss: 0.8710\n",
      "Epoch 7/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 135ms/step - accuracy: 0.5943 - loss: 0.5748 - val_accuracy: 0.5267 - val_loss: 0.8137\n",
      "Epoch 8/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 137ms/step - accuracy: 0.5846 - loss: 0.5616 - val_accuracy: 0.5483 - val_loss: 0.9085\n",
      "Epoch 9/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 141ms/step - accuracy: 0.6296 - loss: 0.5604 - val_accuracy: 0.5017 - val_loss: 0.9348\n",
      "Epoch 10/10\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 145ms/step - accuracy: 0.6079 - loss: 0.5569 - val_accuracy: 0.5450 - val_loss: 0.9821\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.6225 - loss: 0.5478\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.5471 - loss: 0.9141\n",
      "Train Accuracy: 0.6178571581840515\n",
      "Test Accuracy: 0.5450000166893005\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=5000, output_dim=32, input_length=L_val))\n",
    "model_lstm.add(LSTM(32, dropout=0.2))\n",
    "model_lstm.add(Dense(256, activation='relu'))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_lstm.fit(X_train, y_train, epochs=10, batch_size=10, validation_data=(X_test, y_test))\n",
    "\n",
    "_, train_accuracy = model_lstm.evaluate(X_train, y_train)\n",
    "_, test_accuracy = model_lstm.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff0ac51-8de4-486a-81d0-f18e6a5e6c0d",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48013de5-8f51-4ba9-9f2b-3ff525fca0d0",
   "metadata": {},
   "source": [
    "Following are my observations:\n",
    "\n",
    "<ul><li>When padding is set to pre, LSTM has the highest testing accuracy (69%) followed by MLP (64%) and 1D CNN (54.5%). Besides the training accuracy for LSTM is nearly 100%.</li>\n",
    "    <li>When padding is set to post, MLP has the highest testing accuracy (62%) followed by 1D CNN (60%) and LSTM (54.5%). Also, MLP has the highest training accuracy of 81%.</li>\n",
    "    <li>Additionally, we can perform hyperparameter tuning to obtain the best parameters.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d1de8e-c0ec-412e-8f1e-c717db47930a",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464c15b-4ffa-40b4-9f36-044bdd33c328",
   "metadata": {},
   "source": [
    "[1] https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html<br>\n",
    "[2] https://docs.python.org/3/library/os.html#os.listdir<br>\n",
    "[3] https://www.geeksforgeeks.org/python-os-path-join-method/<br>\n",
    "[4] https://stackoverflow.com/questions/39782418/remove-punctuations-in-pandas<br>\n",
    "[5] https://stackoverflow.com/questions/41719259/how-to-remove-numbers-from-string-terms-in-a-pandas-dataframe<br>\n",
    "[6] https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html<br>\n",
    "[7] https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html<br>\n",
    "[8] https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html<br>\n",
    "[9] https://www.geeksforgeeks.org/how-to-convert-pandas-dataframe-into-a-list/<br>\n",
    "[10] https://www.w3schools.com/python/ref_string_join.asp<br>\n",
    "[11] https://www.nltk.org/api/nltk.tokenize.html<br>\n",
    "[12] https://stackoverflow.com/questions/49215099/get-length-of-values-in-pandas-dataframe-column<br>\n",
    "[13] https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html<br>\n",
    "[14] https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html<br>\n",
    "[15] https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.std.html<br>\n",
    "[16] https://seaborn.pydata.org/generated/seaborn.histplot.html<br>\n",
    "[17] https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer<br>\n",
    "[18] https://stackoverflow.com/questions/51956000/what-does-keras-tokenizer-method-exactly-do<br>\n",
    "[19] https://medium.com/analytics-vidhya/understanding-nlp-keras-tokenizer-class-arguments-with-example-551c100f0cbd<br>\n",
    "[20] https://numpy.org/doc/stable/reference/generated/numpy.percentile.html<br>\n",
    "[21] https://hatchjs.com/from-keras-preprocessing-sequence-import-pad_sequences/<br>\n",
    "[22] https://stackoverflow.com/questions/42943291/what-does-keras-io-preprocessing-sequence-pad-sequences-do<br>\n",
    "[23] https://keras.io/api/layers/core_layers/embedding/<br>\n",
    "[24] https://stackoverflow.com/questions/43237124/what-is-the-role-of-flatten-in-keras<br>\n",
    "[25] https://keras.io/api/layers/core_layers/dense/<br>\n",
    "[26] https://machinelearningmastery.com/build-multi-layer-perceptron-neural-network-models-keras/<br>\n",
    "[27] https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/<br>\n",
    "[28] https://stackoverflow.com/questions/53696541/how-to-use-maxpooling1d-with-conv1d<br>\n",
    "[29] https://machinelearningmastery.com/make-predictions-long-short-term-memory-models-keras/<br>\n",
    "[30] https://keras.io/api/layers/recurrent_layers/lstm/<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
